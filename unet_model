digraph {
	graph [size="60.449999999999996,60.449999999999996"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2511401838208 [label="
 (1, 5, 128, 128)" fillcolor=darkolivegreen1]
	2511401743984 [label=ConvolutionBackward0]
	2511401744272 -> 2511401743984
	2511401744272 [label=ReluBackward0]
	2511401744080 -> 2511401744272
	2511401744080 [label=NativeBatchNormBackward0]
	2511401744416 -> 2511401744080
	2511401744416 [label=ConvolutionBackward0]
	2511401744608 -> 2511401744416
	2511401744608 [label=ReluBackward0]
	2511401744752 -> 2511401744608
	2511401744752 [label=NativeBatchNormBackward0]
	2511401744848 -> 2511401744752
	2511401744848 [label=ConvolutionBackward0]
	2511401745040 -> 2511401744848
	2511401745040 [label=CatBackward0]
	2511401745184 -> 2511401745040
	2511401745184 [label=ReluBackward0]
	2511401745328 -> 2511401745184
	2511401745328 [label=NativeBatchNormBackward0]
	2511401745424 -> 2511401745328
	2511401745424 [label=ConvolutionBackward0]
	2511401745616 -> 2511401745424
	2511401745616 [label=ReluBackward0]
	2511401745760 -> 2511401745616
	2511401745760 [label=NativeBatchNormBackward0]
	2511401745856 -> 2511401745760
	2511401745856 [label=ConvolutionBackward0]
	2511401746048 -> 2511401745856
	2511401299376 [label="inc.double_conv.0.weight
 (64, 3, 3, 3)" fillcolor=lightblue]
	2511401299376 -> 2511401746048
	2511401746048 [label=AccumulateGrad]
	2511401745808 -> 2511401745760
	2511401299296 [label="inc.double_conv.1.weight
 (64)" fillcolor=lightblue]
	2511401299296 -> 2511401745808
	2511401745808 [label=AccumulateGrad]
	2511401745664 -> 2511401745760
	2511401299456 [label="inc.double_conv.1.bias
 (64)" fillcolor=lightblue]
	2511401299456 -> 2511401745664
	2511401745664 [label=AccumulateGrad]
	2511401745568 -> 2511401745424
	2511401336896 [label="inc.double_conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2511401336896 -> 2511401745568
	2511401745568 [label=AccumulateGrad]
	2511401745376 -> 2511401745328
	2511401336976 [label="inc.double_conv.4.weight
 (64)" fillcolor=lightblue]
	2511401336976 -> 2511401745376
	2511401745376 [label=AccumulateGrad]
	2511401745232 -> 2511401745328
	2511401337056 [label="inc.double_conv.4.bias
 (64)" fillcolor=lightblue]
	2511401337056 -> 2511401745232
	2511401745232 [label=AccumulateGrad]
	2511401745136 -> 2511401745040
	2511401745136 [label=ConstantPadNdBackward0]
	2511401745520 -> 2511401745136
	2511401745520 [label=ConvolutionBackward0]
	2511401745904 -> 2511401745520
	2511401745904 [label=ReluBackward0]
	2511401745952 -> 2511401745904
	2511401745952 [label=NativeBatchNormBackward0]
	2511401746240 -> 2511401745952
	2511401746240 [label=ConvolutionBackward0]
	2511401746384 -> 2511401746240
	2511401746384 [label=ReluBackward0]
	2511401865424 -> 2511401746384
	2511401865424 [label=NativeBatchNormBackward0]
	2511401865520 -> 2511401865424
	2511401865520 [label=ConvolutionBackward0]
	2511401865712 -> 2511401865520
	2511401865712 [label=CatBackward0]
	2511401865856 -> 2511401865712
	2511401865856 [label=ReluBackward0]
	2511401866000 -> 2511401865856
	2511401866000 [label=NativeBatchNormBackward0]
	2511401866096 -> 2511401866000
	2511401866096 [label=ConvolutionBackward0]
	2511401866288 -> 2511401866096
	2511401866288 [label=ReluBackward0]
	2511401866432 -> 2511401866288
	2511401866432 [label=NativeBatchNormBackward0]
	2511401866528 -> 2511401866432
	2511401866528 [label=ConvolutionBackward0]
	2511401866720 -> 2511401866528
	2511401866720 [label=MaxPool2DWithIndicesBackward0]
	2511401745184 -> 2511401866720
	2511401866672 -> 2511401866528
	2511401337456 [label="down1.maxpool_conv.1.double_conv.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2511401337456 -> 2511401866672
	2511401866672 [label=AccumulateGrad]
	2511401866480 -> 2511401866432
	2511401337536 [label="down1.maxpool_conv.1.double_conv.1.weight
 (128)" fillcolor=lightblue]
	2511401337536 -> 2511401866480
	2511401866480 [label=AccumulateGrad]
	2511401866336 -> 2511401866432
	2511401337616 [label="down1.maxpool_conv.1.double_conv.1.bias
 (128)" fillcolor=lightblue]
	2511401337616 -> 2511401866336
	2511401866336 [label=AccumulateGrad]
	2511401866240 -> 2511401866096
	2511401338016 [label="down1.maxpool_conv.1.double_conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2511401338016 -> 2511401866240
	2511401866240 [label=AccumulateGrad]
	2511401866048 -> 2511401866000
	2511401338096 [label="down1.maxpool_conv.1.double_conv.4.weight
 (128)" fillcolor=lightblue]
	2511401338096 -> 2511401866048
	2511401866048 [label=AccumulateGrad]
	2511401865904 -> 2511401866000
	2511401338176 [label="down1.maxpool_conv.1.double_conv.4.bias
 (128)" fillcolor=lightblue]
	2511401338176 -> 2511401865904
	2511401865904 [label=AccumulateGrad]
	2511401865808 -> 2511401865712
	2511401865808 [label=ConstantPadNdBackward0]
	2511401866192 -> 2511401865808
	2511401866192 [label=ConvolutionBackward0]
	2511401866576 -> 2511401866192
	2511401866576 [label=ReluBackward0]
	2511401866864 -> 2511401866576
	2511401866864 [label=NativeBatchNormBackward0]
	2511401866960 -> 2511401866864
	2511401866960 [label=ConvolutionBackward0]
	2511401867152 -> 2511401866960
	2511401867152 [label=ReluBackward0]
	2511401867296 -> 2511401867152
	2511401867296 [label=NativeBatchNormBackward0]
	2511401867392 -> 2511401867296
	2511401867392 [label=ConvolutionBackward0]
	2511401867584 -> 2511401867392
	2511401867584 [label=CatBackward0]
	2511401867728 -> 2511401867584
	2511401867728 [label=ReluBackward0]
	2511401867872 -> 2511401867728
	2511401867872 [label=NativeBatchNormBackward0]
	2511401867968 -> 2511401867872
	2511401867968 [label=ConvolutionBackward0]
	2511401868160 -> 2511401867968
	2511401868160 [label=ReluBackward0]
	2511401868304 -> 2511401868160
	2511401868304 [label=NativeBatchNormBackward0]
	2511401868400 -> 2511401868304
	2511401868400 [label=ConvolutionBackward0]
	2511401868592 -> 2511401868400
	2511401868592 [label=MaxPool2DWithIndicesBackward0]
	2511401865856 -> 2511401868592
	2511401868544 -> 2511401868400
	2511401338576 [label="down2.maxpool_conv.1.double_conv.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2511401338576 -> 2511401868544
	2511401868544 [label=AccumulateGrad]
	2511401868352 -> 2511401868304
	2511401338656 [label="down2.maxpool_conv.1.double_conv.1.weight
 (256)" fillcolor=lightblue]
	2511401338656 -> 2511401868352
	2511401868352 [label=AccumulateGrad]
	2511401868208 -> 2511401868304
	2511401338736 [label="down2.maxpool_conv.1.double_conv.1.bias
 (256)" fillcolor=lightblue]
	2511401338736 -> 2511401868208
	2511401868208 [label=AccumulateGrad]
	2511401868112 -> 2511401867968
	2511401339136 [label="down2.maxpool_conv.1.double_conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2511401339136 -> 2511401868112
	2511401868112 [label=AccumulateGrad]
	2511401867920 -> 2511401867872
	2511401339216 [label="down2.maxpool_conv.1.double_conv.4.weight
 (256)" fillcolor=lightblue]
	2511401339216 -> 2511401867920
	2511401867920 [label=AccumulateGrad]
	2511401867776 -> 2511401867872
	2511401339296 [label="down2.maxpool_conv.1.double_conv.4.bias
 (256)" fillcolor=lightblue]
	2511401339296 -> 2511401867776
	2511401867776 [label=AccumulateGrad]
	2511401867680 -> 2511401867584
	2511401867680 [label=ConstantPadNdBackward0]
	2511401868064 -> 2511401867680
	2511401868064 [label=ConvolutionBackward0]
	2511401868448 -> 2511401868064
	2511401868448 [label=ReluBackward0]
	2511401868736 -> 2511401868448
	2511401868736 [label=NativeBatchNormBackward0]
	2511401868832 -> 2511401868736
	2511401868832 [label=ConvolutionBackward0]
	2511401869024 -> 2511401868832
	2511401869024 [label=ReluBackward0]
	2511401869168 -> 2511401869024
	2511401869168 [label=NativeBatchNormBackward0]
	2511401869264 -> 2511401869168
	2511401869264 [label=ConvolutionBackward0]
	2511401885904 -> 2511401869264
	2511401885904 [label=CatBackward0]
	2511401886048 -> 2511401885904
	2511401886048 [label=ReluBackward0]
	2511401886192 -> 2511401886048
	2511401886192 [label=NativeBatchNormBackward0]
	2511401886288 -> 2511401886192
	2511401886288 [label=ConvolutionBackward0]
	2511401886480 -> 2511401886288
	2511401886480 [label=ReluBackward0]
	2511401886624 -> 2511401886480
	2511401886624 [label=NativeBatchNormBackward0]
	2511401886720 -> 2511401886624
	2511401886720 [label=ConvolutionBackward0]
	2511401886912 -> 2511401886720
	2511401886912 [label=MaxPool2DWithIndicesBackward0]
	2511401867728 -> 2511401886912
	2511401886864 -> 2511401886720
	2511401339696 [label="down3.maxpool_conv.1.double_conv.0.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2511401339696 -> 2511401886864
	2511401886864 [label=AccumulateGrad]
	2511401886672 -> 2511401886624
	2511401339776 [label="down3.maxpool_conv.1.double_conv.1.weight
 (512)" fillcolor=lightblue]
	2511401339776 -> 2511401886672
	2511401886672 [label=AccumulateGrad]
	2511401886528 -> 2511401886624
	2511401339856 [label="down3.maxpool_conv.1.double_conv.1.bias
 (512)" fillcolor=lightblue]
	2511401339856 -> 2511401886528
	2511401886528 [label=AccumulateGrad]
	2511401886432 -> 2511401886288
	2511401340256 [label="down3.maxpool_conv.1.double_conv.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2511401340256 -> 2511401886432
	2511401886432 [label=AccumulateGrad]
	2511401886240 -> 2511401886192
	2511401340336 [label="down3.maxpool_conv.1.double_conv.4.weight
 (512)" fillcolor=lightblue]
	2511401340336 -> 2511401886240
	2511401886240 [label=AccumulateGrad]
	2511401886096 -> 2511401886192
	2511401340416 [label="down3.maxpool_conv.1.double_conv.4.bias
 (512)" fillcolor=lightblue]
	2511401340416 -> 2511401886096
	2511401886096 [label=AccumulateGrad]
	2511401886000 -> 2511401885904
	2511401886000 [label=ConstantPadNdBackward0]
	2511401886384 -> 2511401886000
	2511401886384 [label=ConvolutionBackward0]
	2511401886768 -> 2511401886384
	2511401886768 [label=ReluBackward0]
	2511401887056 -> 2511401886768
	2511401887056 [label=NativeBatchNormBackward0]
	2511401887152 -> 2511401887056
	2511401887152 [label=ConvolutionBackward0]
	2511401887344 -> 2511401887152
	2511401887344 [label=ReluBackward0]
	2511401887488 -> 2511401887344
	2511401887488 [label=NativeBatchNormBackward0]
	2511401887584 -> 2511401887488
	2511401887584 [label=ConvolutionBackward0]
	2511401887776 -> 2511401887584
	2511401887776 [label=MaxPool2DWithIndicesBackward0]
	2511401886048 -> 2511401887776
	2511401887728 -> 2511401887584
	2511401340816 [label="down4.maxpool_conv.1.double_conv.0.weight
 (1024, 512, 3, 3)" fillcolor=lightblue]
	2511401340816 -> 2511401887728
	2511401887728 [label=AccumulateGrad]
	2511401887536 -> 2511401887488
	2511401553984 [label="down4.maxpool_conv.1.double_conv.1.weight
 (1024)" fillcolor=lightblue]
	2511401553984 -> 2511401887536
	2511401887536 [label=AccumulateGrad]
	2511401887392 -> 2511401887488
	2511401554064 [label="down4.maxpool_conv.1.double_conv.1.bias
 (1024)" fillcolor=lightblue]
	2511401554064 -> 2511401887392
	2511401887392 [label=AccumulateGrad]
	2511401887296 -> 2511401887152
	2511401554464 [label="down4.maxpool_conv.1.double_conv.3.weight
 (1024, 1024, 3, 3)" fillcolor=lightblue]
	2511401554464 -> 2511401887296
	2511401887296 [label=AccumulateGrad]
	2511401887104 -> 2511401887056
	2511401554544 [label="down4.maxpool_conv.1.double_conv.4.weight
 (1024)" fillcolor=lightblue]
	2511401554544 -> 2511401887104
	2511401887104 [label=AccumulateGrad]
	2511401886960 -> 2511401887056
	2511401554624 [label="down4.maxpool_conv.1.double_conv.4.bias
 (1024)" fillcolor=lightblue]
	2511401554624 -> 2511401886960
	2511401886960 [label=AccumulateGrad]
	2511401886816 -> 2511401886384
	2511401555024 [label="up1.up.weight
 (1024, 512, 2, 2)" fillcolor=lightblue]
	2511401555024 -> 2511401886816
	2511401886816 [label=AccumulateGrad]
	2511401886144 -> 2511401886384
	2511401555104 [label="up1.up.bias
 (512)" fillcolor=lightblue]
	2511401555104 -> 2511401886144
	2511401886144 [label=AccumulateGrad]
	2511401885856 -> 2511401869264
	2511401555184 [label="up1.conv.double_conv.0.weight
 (512, 1024, 3, 3)" fillcolor=lightblue]
	2511401555184 -> 2511401885856
	2511401885856 [label=AccumulateGrad]
	2511401869216 -> 2511401869168
	2511401555264 [label="up1.conv.double_conv.1.weight
 (512)" fillcolor=lightblue]
	2511401555264 -> 2511401869216
	2511401869216 [label=AccumulateGrad]
	2511401869072 -> 2511401869168
	2511401555344 [label="up1.conv.double_conv.1.bias
 (512)" fillcolor=lightblue]
	2511401555344 -> 2511401869072
	2511401869072 [label=AccumulateGrad]
	2511401868976 -> 2511401868832
	2511401555744 [label="up1.conv.double_conv.3.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	2511401555744 -> 2511401868976
	2511401868976 [label=AccumulateGrad]
	2511401868784 -> 2511401868736
	2511401555824 [label="up1.conv.double_conv.4.weight
 (512)" fillcolor=lightblue]
	2511401555824 -> 2511401868784
	2511401868784 [label=AccumulateGrad]
	2511401868640 -> 2511401868736
	2511401555904 [label="up1.conv.double_conv.4.bias
 (512)" fillcolor=lightblue]
	2511401555904 -> 2511401868640
	2511401868640 [label=AccumulateGrad]
	2511401868496 -> 2511401868064
	2511401556304 [label="up2.up.weight
 (512, 256, 2, 2)" fillcolor=lightblue]
	2511401556304 -> 2511401868496
	2511401868496 [label=AccumulateGrad]
	2511401867824 -> 2511401868064
	2511401556384 [label="up2.up.bias
 (256)" fillcolor=lightblue]
	2511401556384 -> 2511401867824
	2511401867824 [label=AccumulateGrad]
	2511401867536 -> 2511401867392
	2511401556544 [label="up2.conv.double_conv.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	2511401556544 -> 2511401867536
	2511401867536 [label=AccumulateGrad]
	2511401867344 -> 2511401867296
	2511401556624 [label="up2.conv.double_conv.1.weight
 (256)" fillcolor=lightblue]
	2511401556624 -> 2511401867344
	2511401867344 [label=AccumulateGrad]
	2511401867200 -> 2511401867296
	2511401556704 [label="up2.conv.double_conv.1.bias
 (256)" fillcolor=lightblue]
	2511401556704 -> 2511401867200
	2511401867200 [label=AccumulateGrad]
	2511401867104 -> 2511401866960
	2511401557104 [label="up2.conv.double_conv.3.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2511401557104 -> 2511401867104
	2511401867104 [label=AccumulateGrad]
	2511401866912 -> 2511401866864
	2511401557184 [label="up2.conv.double_conv.4.weight
 (256)" fillcolor=lightblue]
	2511401557184 -> 2511401866912
	2511401866912 [label=AccumulateGrad]
	2511401866768 -> 2511401866864
	2511401557264 [label="up2.conv.double_conv.4.bias
 (256)" fillcolor=lightblue]
	2511401557264 -> 2511401866768
	2511401866768 [label=AccumulateGrad]
	2511401866624 -> 2511401866192
	2511401557664 [label="up3.up.weight
 (256, 128, 2, 2)" fillcolor=lightblue]
	2511401557664 -> 2511401866624
	2511401866624 [label=AccumulateGrad]
	2511401865952 -> 2511401866192
	2511401557744 [label="up3.up.bias
 (128)" fillcolor=lightblue]
	2511401557744 -> 2511401865952
	2511401865952 [label=AccumulateGrad]
	2511401865664 -> 2511401865520
	2511401557904 [label="up3.conv.double_conv.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	2511401557904 -> 2511401865664
	2511401865664 [label=AccumulateGrad]
	2511401865472 -> 2511401865424
	2511401726016 [label="up3.conv.double_conv.1.weight
 (128)" fillcolor=lightblue]
	2511401726016 -> 2511401865472
	2511401865472 [label=AccumulateGrad]
	2511401865328 -> 2511401865424
	2511401726096 [label="up3.conv.double_conv.1.bias
 (128)" fillcolor=lightblue]
	2511401726096 -> 2511401865328
	2511401865328 [label=AccumulateGrad]
	2511401746336 -> 2511401746240
	2511401726496 [label="up3.conv.double_conv.3.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2511401726496 -> 2511401746336
	2511401746336 [label=AccumulateGrad]
	2511401746192 -> 2511401745952
	2511401726576 [label="up3.conv.double_conv.4.weight
 (128)" fillcolor=lightblue]
	2511401726576 -> 2511401746192
	2511401746192 [label=AccumulateGrad]
	2511401746144 -> 2511401745952
	2511401726656 [label="up3.conv.double_conv.4.bias
 (128)" fillcolor=lightblue]
	2511401726656 -> 2511401746144
	2511401746144 [label=AccumulateGrad]
	2511401746000 -> 2511401745520
	2511401727056 [label="up4.up.weight
 (128, 64, 2, 2)" fillcolor=lightblue]
	2511401727056 -> 2511401746000
	2511401746000 [label=AccumulateGrad]
	2511401745280 -> 2511401745520
	2511401727136 [label="up4.up.bias
 (64)" fillcolor=lightblue]
	2511401727136 -> 2511401745280
	2511401745280 [label=AccumulateGrad]
	2511401744992 -> 2511401744848
	2511401727296 [label="up4.conv.double_conv.0.weight
 (64, 128, 3, 3)" fillcolor=lightblue]
	2511401727296 -> 2511401744992
	2511401744992 [label=AccumulateGrad]
	2511401744800 -> 2511401744752
	2511401727376 [label="up4.conv.double_conv.1.weight
 (64)" fillcolor=lightblue]
	2511401727376 -> 2511401744800
	2511401744800 [label=AccumulateGrad]
	2511401744656 -> 2511401744752
	2511401727456 [label="up4.conv.double_conv.1.bias
 (64)" fillcolor=lightblue]
	2511401727456 -> 2511401744656
	2511401744656 [label=AccumulateGrad]
	2511401744560 -> 2511401744416
	2511401727856 [label="up4.conv.double_conv.3.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2511401727856 -> 2511401744560
	2511401744560 [label=AccumulateGrad]
	2511401744368 -> 2511401744080
	2511401727936 [label="up4.conv.double_conv.4.weight
 (64)" fillcolor=lightblue]
	2511401727936 -> 2511401744368
	2511401744368 [label=AccumulateGrad]
	2511401744128 -> 2511401744080
	2511401728016 [label="up4.conv.double_conv.4.bias
 (64)" fillcolor=lightblue]
	2511401728016 -> 2511401744128
	2511401744128 [label=AccumulateGrad]
	2511401744176 -> 2511401743984
	2511401728416 [label="outc.conv.weight
 (5, 64, 1, 1)" fillcolor=lightblue]
	2511401728416 -> 2511401744176
	2511401744176 [label=AccumulateGrad]
	2511401744224 -> 2511401743984
	2511401728496 [label="outc.conv.bias
 (5)" fillcolor=lightblue]
	2511401728496 -> 2511401744224
	2511401744224 [label=AccumulateGrad]
	2511401743984 -> 2511401838208
}
